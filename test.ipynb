{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, global_max_pool\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from absl import app, flags\n",
    "import time\n",
    "import datetime\n",
    "from torch_scatter import scatter\n",
    "from multiprocessing import Pool\n",
    "from featurizing_data import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'GNN'\n",
    "MODEL_TYPE = '1DCNN'\n",
    "device = \"cuda:0\"\n",
    "test_csv_for_ids_path = \"../data/test.csv\"\n",
    "ENSEMBLE = False\n",
    "if ENSEMBLE:\n",
    "    #csv_files = ['results/75M_randomslpit_80epoch/ids_pred_results_best_model.csv',\n",
    "    #             'results/1dcnn/ids_pred_results_best.csv']\n",
    "    #csv_files = ['results/75M_randomslpit_80epoch/ensemble_predictions.csv',\n",
    "    #             'results/1dcnn/ids_pred_results_best.csv']\n",
    "    csv_files = ['results/75M_randomslpit_80epoch/ids_pred_results.csv',\n",
    "                 'results/1dcnn/ids_pred_results_best.csv',\n",
    "                 'results/1dcnn_selfies/ids_pred_results_Epoch31.csv']\n",
    "    # Corresponding weights for each model's predictions\n",
    "    #weights = [0.5, 0.25,0.25]\n",
    "    weights = np.array([0.6323,0.61397,0.6352])\n",
    "    weights = weights/np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33606701, 0.32632463, 0.33760836])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([0.6323,0.61397,0.6352])\n",
    "w = w/np.sum(w)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if MODEL_TYPE == 'GNN':\n",
    "    from train_gnn import *\n",
    "    PACK_NODE_DIM=5\n",
    "    PACK_EDGE_DIM=1\n",
    "    NODE_DIM=PACK_NODE_DIM*8-4\n",
    "    EDGE_DIM=PACK_EDGE_DIM*8-2\n",
    "\n",
    "    # ---hyper-parameters\n",
    "    input_dim = NODE_DIM\n",
    "    edge_dim = EDGE_DIM\n",
    "\n",
    "    emb_dim = 96\n",
    "    num_layers = 4\n",
    "    dropout_rate = 0.3\n",
    "    out_channels = 3\n",
    "\n",
    "\n",
    "    # define model\n",
    "    #model = GNNModel(input_dim, hidden_dim, num_layers, dropout_rate,out_channels).to(device)\n",
    "    model = GNNModel(in_dim=input_dim, edge_dim=edge_dim, emb_dim=emb_dim, num_layers=num_layers,\n",
    "                        out_channels = out_channels,dropout=dropout_rate).to(device)\n",
    "\n",
    "    #results_dir = 'results/gnn_valid_byte_10m'\n",
    "    results_dir = 'results/75M_randomslpit'\n",
    "    results_dir = 'results/75M_randomslpit_80epoch/'\n",
    "else:\n",
    "    from train_1dcnn import *\n",
    "    model = oneDCNN(41).to(device)\n",
    "    results_dir = 'results/1dcnn'\n",
    "    results_dir = 'results/1dcnn_selfies'\n",
    "    results_dir = 'results/1dcnn_selfies_all'\n",
    "\n",
    "    \n",
    "model.load_state_dict(torch.load(os.path.join(results_dir,'best_val.pth')))  # Loading best model of this fold\n",
    "#model.load_state_dict(torch.load(os.path.join(results_dir,'Epoch_29.pth')))  # Loading best model of this fold\n",
    "output_path = os.path.join(results_dir,'ids_pred_results_Epoch_24.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buildingblock1_smiles</th>\n",
       "      <th>buildingblock2_smiles</th>\n",
       "      <th>buildingblock3_smiles</th>\n",
       "      <th>molecule_smiles</th>\n",
       "      <th>is_BRD4</th>\n",
       "      <th>is_HSA</th>\n",
       "      <th>is_sEH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ncnc3c2...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(NCC2(O)CCCC2(C)C)nc(Nc2ccc(C...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>244</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2sc(Cl)c...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>394</td>\n",
       "      <td>C#CCCC[C@H](Nc1nc(NCC2CCC(SC)CC2)nc(Nc2ccc(C=C...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buildingblock1_smiles  buildingblock2_smiles  buildingblock3_smiles  \\\n",
       "0                      0                     17                     17   \n",
       "1                      0                     17                     87   \n",
       "2                      0                     17                     99   \n",
       "3                      0                     17                    244   \n",
       "4                      0                     17                    394   \n",
       "\n",
       "                                     molecule_smiles  is_BRD4  is_HSA  is_sEH  \n",
       "0  C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C...     True    True    True  \n",
       "1  C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ncnc3c2...     True    True    True  \n",
       "2  C#CCCC[C@H](Nc1nc(NCC2(O)CCCC2(C)C)nc(Nc2ccc(C...     True    True    True  \n",
       "3  C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2sc(Cl)c...     True    True    True  \n",
       "4  C#CCCC[C@H](Nc1nc(NCC2CCC(SC)CC2)nc(Nc2ccc(C=C...     True    True    True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {'buildingblock1_smiles': np.int16, 'buildingblock2_smiles': np.int16, 'buildingblock3_smiles': np.int16,\n",
    "          'binds_BRD4':np.byte, 'binds_HSA':np.byte, 'binds_sEH':np.byte}\n",
    "\n",
    "test_df = pd.read_csv('../shrunken_data/test.csv', dtype = dtypes)\n",
    "print(len(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model, val_loader,device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #for t, index in enumerate(np.arange(0,len(idx),batch_size)):\n",
    "        for inputs in val_loader:  # Assuming you have a DataLoader named val_loader\n",
    "            #index_batch = idx[index:index+batch_size]\n",
    "            #batch = dotdict(\n",
    "            #    graph = my_collate(data,index_batch,device=device),\n",
    "            #)\n",
    "            #print(inputs[0].shape)\n",
    "            #if is_labeled:\n",
    "            #input = inputs[0]\n",
    "            output = model(inputs[0].to(device)) \n",
    "            predictions.extend(torch.sigmoid(output).tolist())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENSEMBLE is False:       \n",
    "    if MODEL_TYPE == 'GNN': \n",
    "        print('----Featurizing testing data -----')\n",
    "        smiles_list_test = test_df['molecule_smiles'].tolist()\n",
    "        with Pool(processes=64) as pool:\n",
    "            test_dataset = list(pool.imap(smile_to_graph, smiles_list_test))\n",
    "\n",
    "        # Predict\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "        predictions = predict_with_model(model, test_loader,device,False)\n",
    "        y_pred_and_ids_df = select_and_save_predictions_with_ids(predictions,test_df,test_csv_for_ids_path)\n",
    "        y_pred_and_ids_df.to_csv(output_path,index=False)\n",
    "    else:\n",
    "        MAX_LEN = 130 # 142\n",
    "        FEATURES = [f'enc{i}' for i in range(MAX_LEN)]\n",
    "        #test_data = pd.read_parquet('test_enc.parquet')\n",
    "        test_data = pd.read_parquet('test_enc_selfies.parquet')\n",
    "        \n",
    "        test_idx = np.array(test_data.index)\n",
    "        X_test = torch.tensor(test_data.loc[test_idx, FEATURES].values, dtype=torch.int)\n",
    "        # Create TensorDatasets\n",
    "        test_dataset = TensorDataset(X_test)\n",
    "        tst = pd.read_csv(test_csv_for_ids_path,index_col=False)#[:len(y_pred_df)]\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "        predictions = predict_with_model(model, test_loader,device)\n",
    "        predictions = np.array(predictions)\n",
    "        tst['binds'] = 0\n",
    "        tst.loc[tst['protein_name']=='BRD4', 'binds'] = predictions[(tst['protein_name']=='BRD4').values, 0]\n",
    "        tst.loc[tst['protein_name']=='HSA', 'binds'] = predictions[(tst['protein_name']=='HSA').values, 1]\n",
    "        tst.loc[tst['protein_name']=='sEH', 'binds'] = predictions[(tst['protein_name']=='sEH').values, 2]\n",
    "        tst[['id', 'binds']].to_csv(output_path, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          4.814573e-06\n",
       "1          2.401210e-05\n",
       "2          1.750874e-09\n",
       "3          5.170739e-10\n",
       "4          1.157709e-06\n",
       "               ...     \n",
       "1674891    2.709554e-06\n",
       "1674892    2.382939e-07\n",
       "1674893    3.778671e-06\n",
       "1674894    1.530312e-04\n",
       "1674895    8.083007e-07\n",
       "Name: binds, Length: 1674896, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst['binds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if ENSEMBLE:\n",
    "    # List of CSV files containing predictions\n",
    "\n",
    "    weighted_predictions = None\n",
    "\n",
    "    # Loop through each file and weight\n",
    "    for file, weight in zip(csv_files, weights):\n",
    "        # Read predictions from the current file\n",
    "        #in_path = os.path.join(results_dir,file)\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Ensure the 'prediction' column exists\n",
    "        if 'binds' not in df.columns:\n",
    "            raise ValueError(f\"'prediction' column not found in {file}\")\n",
    "        \n",
    "        # Multiply the predictions by the corresponding weight\n",
    "        weighted_pred = df['binds'] * weight\n",
    "        \n",
    "        # If it's the first model, initialize the weighted_predictions\n",
    "        if weighted_predictions is None:\n",
    "            weighted_predictions = weighted_pred\n",
    "        else:\n",
    "            # Add the weighted predictions to the ensemble\n",
    "            weighted_predictions += weighted_pred\n",
    "\n",
    "\n",
    "    test = pd.read_csv('../data/test.csv',index_col=False)#[:len(y_pred_df)]\n",
    "    test_ids = pd.DataFrame(test.id)\n",
    "    ensemble_df = pd.concat([test_ids,weighted_predictions],axis=1)\n",
    "    # Create a DataFrame for the ensemble predictions\n",
    "\n",
    "    # Save the ensemble predictions to a new CSV file\n",
    "    output_path = os.path.join(results_dir,'ensemble_predictions_gnn_1dcnnsmiles_1dcnnselfies_weights_adjusted.csv')\n",
    "\n",
    "    ensemble_df.to_csv(output_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/1dcnn_selfies/ids_pred_results_epoch29.csv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdkaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
